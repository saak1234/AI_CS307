{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hHlMYXro1-do"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Node class represents a graph node with:\n",
        "Parent, State, and Cost attributes.\n",
        "\n",
        "It uses built-in methods:\n",
        "\n",
        "* hash: Generates a unique hash for the node.\n",
        "* eq: Checks node equality (==).\n",
        "* ne: Checks node inequality (!=).\n",
        "* str: Returns the nodeâ€™s state as a string.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eiJpps0xbm-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, parent, state, pcost, hcost, action=None):\n",
        "        self.parent = parent\n",
        "        self.state = state\n",
        "        self.action = action\n",
        "        self.pcost = pcost\n",
        "        self.hcost = hcost\n",
        "        self.cost = pcost + hcost\n",
        "    def __hash__(self):\n",
        "        return hash(str(self.state.flatten()))\n",
        "    def __str__(self):\n",
        "        return str(self.state)\n",
        "    def __eq__(self, other):\n",
        "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten()))\n",
        "    def __ne__(self, other):\n",
        "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
      ],
      "metadata": {
        "id": "0gsnkAmO4Lph"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PriorityQueue class manages nodes based on their costs, allowing the retrieval of the node with the lowest cost for BFS. It includes the following methods:\n",
        "\n",
        "1.push: Adds a node to the queue.\n",
        "2.pop: Removes and returns the node with the lowest cost.\n",
        "3.is_empty: Checks if the queue is empty.\n",
        "4.__len__: Returns the number of nodes in the queue.\n",
        "5.__str__: Provides a string representation of the queue."
      ],
      "metadata": {
        "id": "sF3AMHARc3MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PriorityQueue():\n",
        "    def __init__(self):\n",
        "        self.queue = []\n",
        "        self.hashes = {}\n",
        "    def push(self, node):\n",
        "        if hash(node) not in self.hashes:\n",
        "            self.hashes[hash(node)] = 1\n",
        "            self.queue.append(node)\n",
        "    def pop(self):\n",
        "        next_state = None\n",
        "        state_cost = 10**18\n",
        "        index = -1\n",
        "        for i in range(len(self.queue)):\n",
        "            if self.queue[i].cost<state_cost:\n",
        "                state_cost = self.queue[i].cost\n",
        "                index = i\n",
        "\n",
        "        return self.queue.pop(index)\n",
        "    def is_empty(self):\n",
        "\n",
        "        return len(self.queue)==0\n",
        "    def __str__(self):\n",
        "        l = []\n",
        "        for i in self.queue:\n",
        "            l.append(i.state)\n",
        "        return str(l)\n",
        "    def __len__(self):\n",
        "        return len(self.queue)"
      ],
      "metadata": {
        "id": "gGrgRkyU4QLE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Class\n",
        "Defines the setting for the agent with:\n",
        "\n",
        "1.Actions: Available actions.\n",
        "\n",
        "2.Depth: Maximum solution depth.\n",
        "\n",
        "3.Goal State: Target state.\n",
        "\n",
        "4.Start State: Initial state based on depth.\n",
        "\n",
        "Functions:\n",
        "\n",
        "1.get_start_state: Retrieves the start state.\n",
        "\n",
        "2.reached_goal: Checks if goal is reached.\n",
        "\n",
        "3.get_next_states: Returns possible next states.\n",
        "\n",
        "4.generate_start_state: Creates start state by executing moves up to the specified depth."
      ],
      "metadata": {
        "id": "ulf7RSeksojt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment():\n",
        "    def __init__(self, start_state=None, goal_state=None):\n",
        "        self.actions = [1,2,3,4]\n",
        "        if goal_state is None:\n",
        "            self.goal_state = self.generate_goal_state()\n",
        "        else:\n",
        "            self.goal_state = goal_state\n",
        "        if start_state is None:\n",
        "            self.start_state = self.generate_start_state()\n",
        "        else:\n",
        "            self.start_state = start_state\n",
        "    def generate_start_state(self):\n",
        "        start = np.zeros((7,7))\n",
        "        x = (0,1,5,6)\n",
        "        y = (0,1,5,6)\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                start[i][j] = -1;\n",
        "        x = (2,3,4)\n",
        "        y = range(7)\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                start[i][j] = 1\n",
        "                start[j][i] = 1\n",
        "        start[3][3] = 0\n",
        "        return start\n",
        "    def generate_goal_state(self):\n",
        "        goal = np.zeros((7,7))\n",
        "        x = (0,1,5,6)\n",
        "        y = (0,1,5,6)\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                goal[i][j] = -1;\n",
        "        x = (2,3,4)\n",
        "        y = range(7)\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                goal[i][j] = 0\n",
        "                goal[j][i] = 0\n",
        "        goal[3][3] = 1\n",
        "        return goal\n",
        "    def get_start_state(self):\n",
        "        return self.start_state\n",
        "    def get_goal_state(self):\n",
        "        return self.goal_state\n",
        "    def get_next_states(self, state):\n",
        "        new_states = []\n",
        "        spaces = []\n",
        "        for i in range(7):\n",
        "            for j in range(7):\n",
        "                if state[i][j]==0:\n",
        "                    spaces.append((i,j))\n",
        "        for space in spaces:\n",
        "            x, y = space\n",
        "            if x>1:\n",
        "                if state[x-1][y]==1 and state[x-2][y]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x-2][y] = 0\n",
        "                    new_state[x-1][y] = 0\n",
        "                    action = f'({x-2}, {y}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "            if x<5:\n",
        "                if state[x+1][y]==1 and state[x+2][y]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x+2][y] = 0\n",
        "                    new_state[x+1][y] = 0\n",
        "                    action = f'({x+2}, {y}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "            if y>1:\n",
        "                if state[x][y-1]==1 and state[x][y-2]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x][y-2] = 0\n",
        "                    new_state[x][y-1] = 0\n",
        "                    action = f'({x}, {y-2}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "            if y<5:\n",
        "                if state[x][y+1]==1 and state[x][y+2]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x][y+2] = 0\n",
        "                    new_state[x][y+1] = 0\n",
        "                    action = f'({x}, {y+2}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "        return new_states\n",
        "    def reached_goal(self, state):\n",
        "        for i in range(7):\n",
        "            for j in range(7):\n",
        "                if state[i,j] != self.goal_state[i,j]:\n",
        "                    return False\n",
        "        return True"
      ],
      "metadata": {
        "id": "EfgOXgnA4SV2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic0(curr_state):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "m-VY4Yxr4a-J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic1(curr_state):\n",
        "    cost = 0\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            if curr_state[i][j]==1:\n",
        "                cost += abs(i-3)+abs(j-3)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "FvkpxmZ74dez"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic2(curr_state):\n",
        "    cost = 0\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            if curr_state[i][j]==1:\n",
        "                cost += 2**(max(abs(i-3),abs(j-3)))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "jqndTBAg4gWO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent1:\n",
        "    def __init__(self, env, heuristic):\n",
        "        self.frontier = PriorityQueue()\n",
        "        self.explored = dict()\n",
        "        self.start_state = env.get_start_state()\n",
        "        self.goal_state = env.get_goal_state()\n",
        "        self.env = env\n",
        "        self.goal_node = None\n",
        "        self.heuristic = heuristic\n",
        "    def run(self):\n",
        "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
        "        self.frontier.push(init_node)\n",
        "        start = time()\n",
        "        while not self.frontier.is_empty():\n",
        "            curr_node = self.frontier.pop()\n",
        "            next_states = self.env.get_next_states(curr_node.state)\n",
        "            if hash(curr_node) in self.explored:\n",
        "                continue\n",
        "            self.explored[hash(curr_node)] = curr_node\n",
        "            if self.env.reached_goal(curr_node.state):\n",
        "                print(\"Reached goal!\")\n",
        "                self.goal_node = curr_node\n",
        "                break\n",
        "            goal_state = self.env.get_goal_state()\n",
        "            l = []\n",
        "            for state in next_states:\n",
        "                hcost = self.heuristic(state[0])\n",
        "                node = Node(parent=curr_node, state=state[0], pcost=curr_node.pcost+1, hcost=hcost, action=state[1])\n",
        "                self.frontier.push(node)\n",
        "        end = time()\n",
        "        print(end - start)\n",
        "        return end-start\n",
        "    def print_nodes(self):\n",
        "        node = self.goal_node\n",
        "        l = []\n",
        "        while node is not None:\n",
        "            l.append(node)\n",
        "            node = node.parent\n",
        "        step = 1\n",
        "        for node in l[::-1]:\n",
        "            print(\"Step: \",step)\n",
        "            print(node.action)\n",
        "            step+=1"
      ],
      "metadata": {
        "id": "JNcVLw_E4jJL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "for i in range(5):\n",
        "    agent = Agent1(Environment(), heuristic2)\n",
        "    t+=agent.run()\n",
        "print(\"Average time\", t/5)\n",
        "print(\"Number of nodes explored:\", len(agent.explored))\n",
        "print(\"Number of nodes in frontier:\", len(agent.frontier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_vuM1MD4l6x",
        "outputId": "c0803bcf-6bcb-4946-e9bc-82df4ee25634"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached goal!\n",
            "88.25390720367432\n",
            "Reached goal!\n",
            "84.53179788589478\n",
            "Reached goal!\n",
            "84.84414601325989\n",
            "Reached goal!\n",
            "84.88477826118469\n",
            "Reached goal!\n",
            "86.88706994056702\n",
            "Average time 85.88033986091614\n",
            "Number of nodes explored: 33353\n",
            "Number of nodes in frontier: 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent2:\n",
        "    def __init__(self, env, heuristic):\n",
        "        self.frontier = PriorityQueue()\n",
        "        self.explored = dict()\n",
        "        self.start_state = env.get_start_state()\n",
        "        self.goal_state = env.get_goal_state()\n",
        "        self.env = env\n",
        "        self.goal_node = None\n",
        "        self.heuristic = heuristic\n",
        "    def run(self):\n",
        "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
        "        self.frontier.push(init_node)\n",
        "        start = time()\n",
        "        while not self.frontier.is_empty():\n",
        "            curr_node = self.frontier.pop()\n",
        "            next_states = self.env.get_next_states(curr_node.state)\n",
        "            if hash(curr_node) in self.explored:\n",
        "                continue\n",
        "            self.explored[hash(curr_node)] = curr_node\n",
        "            if self.env.reached_goal(curr_node.state):\n",
        "                print(\"Reached goal!\")\n",
        "                self.goal_node = curr_node\n",
        "                break\n",
        "            goal_state = self.env.get_goal_state()\n",
        "            l = []\n",
        "            for state in next_states:\n",
        "                hcost = self.heuristic(state[0])\n",
        "                node = Node(parent=curr_node, state=state[0], pcost=0, hcost=hcost, action=state[1])\n",
        "                self.frontier.push(node)\n",
        "        end = time()\n",
        "        print(end - start)\n",
        "        return end-start\n",
        "    def print_nodes(self):\n",
        "        node = self.goal_node\n",
        "        l = []\n",
        "        while node is not None:\n",
        "            l.append(node)\n",
        "            node = node.parent\n",
        "        step = 1\n",
        "        for node in l[::-1]:\n",
        "            print(\"Step: \",step)\n",
        "            print(node.action)\n",
        "            #print(node)\n",
        "            step+=1\n",
        "t = 0\n",
        "for i in range(5):\n",
        "    agent = Agent2(Environment(), heuristic2)\n",
        "    t+=agent.run()\n",
        "print(\"Average time\", t/5)\n",
        "print(\"Number of nodes explored:\", len(agent.explored))\n",
        "print(\"Number of nodes in frontier:\", len(agent.frontier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk_G2Ngb7igP",
        "outputId": "e5c052f0-c23d-497f-8e55-c4b167e1d5de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached goal!\n",
            "90.36752367019653\n",
            "Reached goal!\n",
            "91.34847521781921\n",
            "Reached goal!\n",
            "90.84491062164307\n",
            "Reached goal!\n",
            "91.3160936832428\n",
            "Reached goal!\n",
            "91.35780787467957\n",
            "Average time 91.04696221351624\n",
            "Number of nodes explored: 35997\n",
            "Number of nodes in frontier: 133\n"
          ]
        }
      ]
    }
  ]
}